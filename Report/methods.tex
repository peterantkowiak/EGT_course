\section{Methods}


\subsection{Non-spatial PD and HD}

The first step for our model was to calculate the average payoff for cooperators and defectors in the non-spatial PD and HD. We used p for the probability of players being defectors (probability of cooperators is $1-p$). Due to the payoff matrix of the HD game we used $P_{c}=0.5*(1-p)*c+b-c$ and $P_{d}=p*b$. For the PD average pay-off for cooperators changes: $P_{c}=(1-p)*b-c$. These average Payoffs reduce or increase the fitness of the single players. In an iterated game fitter players reproduce and get a higher percentage of the population - in our case cooperators or defectors. For the next iteration (reproduction) of the game p is now calculated by comparing the fitness of defectors with the fitness of all players.
 
\subsection{Spatial structure and neighborhood size}
In our spatial games we used a 50 x 50 square lattice. Every patch represents one player. The whole lattice was updated synchronically. We introduced different neighborhood-sizes from four to 24 neighbors in our model. Therefore we worked with four different sizes of radius ($1$, $\sqrt[2]{2}$, $2$, $2*\sqrt[2]{2}$, caliber of players as unit) around the players for five neighborhood-sizes (4, 8, 12, 24). Instead of using $p$, which was the probability to be a defector in the non-spatial game, we inserted a local probability $p_l$ in the average payoff terms. These were calculated with the neighbors' probabilities to be a cooperator or defector. Herewith fitness of the players is calculated again facing the neighborhood. As opposed to the non-spatial game the change of the strategy in the next round of the game was not calculated for the whole population, it was calculated for the single player (in our simulation patch). The players randomly chose neighbors for the competition. Then the transition probability (probability to change strategy) was calculated with $p_{c} = Z/\alpha$. $Z$ is the difference between the fitness of the competitor $F_c$ and the own fitness $F$. $\alpha$ is the maximum difference between the payoffs, and equals $\alpha=T-P=b$ in the HD game and $\alpha=T-S=b+c$ in the PD. This correction term ensures $p_{c}$ values between $0$ and $1$. If $Z>0$, the player changed the strategy with the probability $p_{c}$, which represents a reproduction of the fitter players.

\subsection{Effect of mixed strategies in the spatial and non-spatial Hawk-Dove game}
In our simulation for the HD with mixed strategies every player was characterized by the probability $p$ to show dove-like behavior which in turn was subject to a small mutation rate to allow for evolution in the game. The initial heterogeneity of the players was randomly chosen from a normal distribution. The mean of the normal distribution was the equilibrium strategy of well-mixed populations $p_{w} = (1-c/(2*b-v))$, calculated from the cost-to-benefit ratio. The standard deviation was set to $0.02$. The boundaries of the distribution were set to $0$ and $1$ to get a fitting value for the probability. The following procedure was the same as for the models with spatial structure, but with different mathematics to introduce the mutation. The average payoff $P_{mix} = p_{w}*p_{n}*(b-(0.5*c))+ p_{w}*(1-p_{n})*(b-c)+(1-p_{w})*p_{n}*b$ was $P$ with $p_n$ as the mean strategy of all interacting neighbors. More generally the term is $P_{mix}  = p_{w}*p_{n}*R+ p_{w}*(1-p_{n})*S+(1-p_{w})*p_{n}*T+(1-p_{w})*(1-p_{n})*P$, which means that the payoff differences between neighboring individuals are very small. The update rule for pure strategies had a very small probability of change, which made the simulation very slow. For that reason a non-linear term was introduced for the change-probability: $p_{cmix} = [1 + exp(-z/k)]^{-1}$.

\subsection{Simulations with NetLogo, plots with R}
The simulations were programmed agent-based with NetLogo \citep{Wilensky1999}. The modeling of the non-spatial and the spatial HD and PD with different neighborhood-sizes were ran with the Behavior Space of the program. For having robust results we ran the simulation 10 times for 5000 time-steps with varying costs and benefit set to 1. The costs we calculated according to the replicator dynamics, the equilibrium frequency of cooperators in the HD with $r=c/(2*b-c)$. Therefore $c=(2*r/(1+r))$ with a sequence for r from 0 to 1 with an 0.05 step. The population had the size  of 50 x 50 patches, that means 2500 players. The mixed strategy games ran for 10.000 time-steps to make sure that we the equilibrium level. To compare the models we plotted the results in R \citep{R} with the frequency of cooperation on the y-axis and the cost-to-benefit ration on the x-axis. 

